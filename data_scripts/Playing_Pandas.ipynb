{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Aim : \n",
    "1, Take damn.txt and rep_set_tax_assignments.txt\n",
    "2, Make a data frame\n",
    "# OTU NC1_c NC2_c etc K O P C F G S U\n",
    "Popluate with NULL if no values are available\n",
    "\n",
    "3, Make a def to subset all the rows which has P == 'Firmicutes' etc. and Sample == NC1\n",
    "it should give the results like this (is another df)\n",
    "# OTU NC1 K O P C F G S U\n",
    "\n",
    "4, def : df to counter\n",
    "input : # OTU NC1 K O P C F G S U\n",
    "output : # OTU NC1_c\n",
    "\n",
    "5. Compare two outputs\n",
    "subset the df1 and df2\n",
    "df1_NC1  \n",
    "otu1 12\n",
    "otu2 34\n",
    "otu3 3 etc \n",
    "\n",
    "df2_NC1  \n",
    "otu1 23\n",
    "otu2 4\n",
    "otu3 66 etc \n",
    "\n",
    "make a matplotlib.plt of these two Series\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PlayBioms.py\t      data_scripts.Rproj     modified_damn.csv\r\n",
      "Playing_Pandas.ipynb  final_otu_map.txt      rep_set_tax_assignments.txt\r\n",
      "ahist.R\t\t      final_otu_map_mc1.txt  sofar.R\r\n",
      "bhist.R\t\t      final_qiime.R\t     ssfinal_otu_map.txt\r\n",
      "checkingRphyloseq.R   jiaco2roshan.R\t     ssrep_set_tax_assignments.txt\r\n",
      "damn.txt\t      mapping_file2.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1 = \"damn.txt\"\n",
    "with open(f1, 'r')  as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OTU\t HFD_c\tHFS_c\tNC_c\tTotal\n",
      "206494 \t18 \t0 \t21 \t39\n",
      "1800048 \t0 \t2 \t0 \t2\n",
      "541135 \t9 \t0 \t65 \t74\n",
      "276629 \t5 \t2 \t106 \t113\n",
      "1036749 \t4 \t8 \t0 \t12\n",
      "259732 \t2 \t0 \t0 \t2\n",
      "276195 \t25 \t0 \t8 \t33\n",
      "186233 \t0 \t2 \t0 \t2\n",
      "276620 \t0 \t0 \t2 \t2\n",
      "373909 \t24 \t12 \t12 \t48\n"
     ]
    }
   ],
   "source": [
    "# This piece of code gives the counts based on groups \n",
    "\n",
    "newdt = {}\n",
    "otus =[]\n",
    "print \"OTU\\t HFD_c\\tHFS_c\\tNC_c\\tTotal\"\n",
    "for e,i in enumerate(data[0:10]):\n",
    "    i = i.strip(\"\\n\") \n",
    "    #print e, i.split(\"\\t\")[1],';'.join(i.split(\"\\t\")[2:])\n",
    "    #print e, i.split(\"\\t\")[0], len(i.split(\"\\t\"))-1\n",
    "    otu = i.split(\"\\t\")[0]\n",
    "    #print otu\n",
    "    otus.append(otu)\n",
    "    readids = i.split(\"\\t\")[1:]\n",
    "    #newdt[otu] =  '|'.join(readids).replace(\" \",\"\")\n",
    "    NCs, HFD, HFS = [], [], []\n",
    "    for p,x in enumerate(readids):\n",
    "        #print \"Line :\", e+1,p+1 ,x\n",
    "        if \"NC\" in x:\n",
    "            NCs.append(x)\n",
    "        elif \"HFD\" in x:\n",
    "            HFD.append(x)\n",
    "        elif \"HFS\" in x:\n",
    "            HFS.append(x)\n",
    "        #print HFD, HFS, NCs\n",
    "    HFD_c=len(HFD)\n",
    "    HFS_c=len(HFS)\n",
    "    NC_c = len(NCs)\n",
    "    #print otu, \"HFD:\" ,HFD_c, \"HFS:\",HFS_c,\"NCs:\",NC_c, \"Total:\", HFD_c + HFS_c + NC_c\n",
    "    print otu,\"\\t\", HFD_c,\"\\t\", HFS_c,\"\\t\", NC_c,\"\\t\", HFD_c + HFS_c + NC_c\n",
    "#print newdt\n",
    "#keys =  [ k for k in newdt.keys() ]\n",
    "#testS = pd.Series(newdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#SampleID\tBarcodeSequence\tLinkerPrimerSequence\tInputFileName\tTreatment\tReplicate\tDescription\r\n",
      "HFD.1\tGAGGGC\t\t/anas/roshan-current/i2mc/burcelin/miseq/testV/merged_data/HFD_1.fasta\tHFD\t1\tdesc\r\n",
      "HFD.2\tTACAAG\t\t/anas/roshan-current/i2mc/burcelin/miseq/testV/merged_data/HFD_2.fasta\tHFD\t2\tdesc\r\n",
      "HFD.3\tCGTTTC\t\t/anas/roshan-current/i2mc/burcelin/miseq/testV/merged_data/HFD_3.fasta\tHFD\t3\tdesc\r\n"
     ]
    }
   ],
   "source": [
    "!head -4 mapping_file2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use mapping file to get the Sample Ids\n",
    "mf =pd.read_csv(\"mapping_file2.txt\" , header=False, sep=\"\\t\")\n",
    "SampleID = mf[\"#SampleID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create several regex complie objs at once\n",
    "def re_compiler(SampleID):\n",
    "    \"\"\"pandasSeries | list->list\n",
    "    Returns a list of tuples with pattern and re compiler obj\n",
    "    \"\"\"\n",
    "    r =[]\n",
    "    for i in SampleID:\n",
    "        y = i \n",
    "        y2 = re.compile(i)\n",
    "        r.append((y,y2))\n",
    "    return(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HFD.1', re.compile(r'HFD.1')),\n",
       " ('HFD.2', re.compile(r'HFD.2')),\n",
       " ('HFD.3', re.compile(r'HFD.3'))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = re_compiler(SampleID)\n",
    "pp[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def line_to_counts(line, pp):\n",
    "    result = {}\n",
    "    for i in line:\n",
    "        for p in pp:\n",
    "            if p[1].match(i):\n",
    "                #print p[0], \"line found: \", i\n",
    "                if not p[0] in result:\n",
    "                    result[p[0]] =1\n",
    "                else:\n",
    "                    result[p[0]] +=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def line_to_counts2(line, pp):\n",
    "    \"\"\"list,list->list\n",
    "    Returns a list of counts for each pattern in pp\n",
    "    pp is a tuple of patten and re compiler \n",
    "    made from function re_compiler\n",
    "    >>>lines_to_counts2(line, pp)\n",
    "    [6, 10, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0]\n",
    "    \"\"\"\n",
    "    dict1 = {}\n",
    "    result=[]\n",
    "    for i in line:\n",
    "        for p in pp:\n",
    "            if p[1].match(i):\n",
    "                #print p[0], \"line found: \", i\n",
    "                if not p[0] in result:\n",
    "                    dict1[p[0]] =1\n",
    "                else:\n",
    "                    dict1[p[0]] +=1\n",
    "    for i in pp:\n",
    "        #print i[0]\n",
    "        if dict1.get(i[0]):\n",
    "            #print i,result.get(i)\n",
    "            result.append(dict1.get(i[0]))\n",
    "        else:\n",
    "            #print i,0\n",
    "            result.append(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OTU ['HFD.1', 'HFD.2', 'HFD.3', 'HFD.4', 'HFD.5', 'HFDS.1', 'HFDS.2', 'HFDS.3', 'HFDS.4', 'HFDS.5', 'NC.1', 'NC.2', 'NC.3', 'NC.4', 'NC.5']\n",
      "206494 [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "1800048 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "541135 [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
      "276629 [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "1036749 [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "259732 [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "276195 [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "186233 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "276620 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "373909 [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# This piece of code gives the counts based on subgroups\n",
    "otus =[]\n",
    "print \"OTU\",[ i[0] for i in pp]\n",
    "for e,i in enumerate(data[0:10]):\n",
    "    i = i.strip(\"\\n\")\n",
    "    otu = i.split(\"\\t\")[0]\n",
    "    print otu,\n",
    "    readids = i.split(\"\\t\")[1:]\n",
    "    print line_to_counts2(readids, pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a DF of OTUs counts and taxa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
